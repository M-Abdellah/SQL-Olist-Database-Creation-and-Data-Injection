{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c729e2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import urllib\n",
    "\n",
    "# ==============================\n",
    "# SQL Server Connection\n",
    "# ==============================\n",
    "\n",
    "server = r'WAHEED\\SQLEXPRESS'\n",
    "database = 'Olist DB'  # <-- CHANGE THIS\n",
    "\n",
    "connection_string = (\n",
    "    \"Driver={ODBC Driver 17 for SQL Server};\"\n",
    "    f\"Server={server};\"\n",
    "    f\"Database={database};\"\n",
    "    \"Trusted_Connection=yes;\"\n",
    ")\n",
    "\n",
    "params = urllib.parse.quote_plus(connection_string)\n",
    "engine = create_engine(\n",
    "    f\"mssql+pyodbc:///?odbc_connect={params}\",\n",
    "    fast_executemany=True\n",
    ")\n",
    "\n",
    "# ==============================\n",
    "# Load CSV Files\n",
    "# ==============================\n",
    "\n",
    "df1 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_customers_dataset.csv\")\n",
    "df2 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_orders_dataset.csv\")\n",
    "df3 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_order_payments_dataset.csv\")\n",
    "\n",
    "df4 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_order_reviews_dataset.csv\")\n",
    "df5 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_sellers_dataset.csv\")\n",
    "df6 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\product_category_name_translation.csv\")\n",
    "df7 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_products_dataset.csv\")\n",
    "df8 = pd.read_csv(r\"E:\\DEPI Grad-Project\\archive (2)\\olist_order_items_dataset.csv\")\n",
    "\n",
    "# ==============================\n",
    "# Upload to SQL Server\n",
    "# ==============================\n",
    "\n",
    "df1.to_sql('Customers', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "df2['order_purchase_timestamp'] = pd.to_datetime(df2['order_purchase_timestamp'],errors='coerce')\n",
    "df2['order_approved_at'] = pd.to_datetime(df2['order_approved_at'],errors='coerce')\n",
    "df2['order_delivered_carrier_date'] = pd.to_datetime(df2['order_delivered_carrier_date'],errors='coerce')\n",
    "df2['order_delivered_customer_date'] = pd.to_datetime(df2['order_delivered_customer_date'],errors='coerce')\n",
    "df2['order_estimated_delivery_date'] = pd.to_datetime(df2['order_estimated_delivery_date'],errors='coerce')\n",
    "\n",
    "df2.to_sql('Orders', engine, if_exists='append', index=False, chunksize=1000)\n",
    "df3.to_sql('Order_Payments', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "df4['review_creation_date'] = pd.to_datetime(df4['review_creation_date'],errors='coerce')\n",
    "df4['review_answer_timestamp'] = pd.to_datetime(df4['review_answer_timestamp'],errors='coerce')\n",
    "\n",
    "df4.to_sql('Order_Reviews', engine, if_exists='append', index=False, chunksize=1000)\n",
    "df5.to_sql('Sellers', engine, if_exists='append', index=False, chunksize=1000)\n",
    "df6.to_sql('Product_Category_Name_Translation', engine, if_exists='append', index=False, chunksize=1000)\n",
    "df7.to_sql('Products', engine, if_exists='append', index=False, chunksize=1000)\n",
    "df8.to_sql('Order_Items', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "print(\"✅ All tables uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b632e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df4['review_id'].dropna(inplace=True)\n",
    "df4.drop_duplicates(subset=['review_id'],inplace=True)\n",
    "df4['review_creation_date'] = pd.to_datetime(df4['review_creation_date'],errors='coerce')\n",
    "df4['review_answer_timestamp'] = pd.to_datetime(df4['review_answer_timestamp'],errors='coerce')\n",
    "\n",
    "df4.to_sql('Order_Reviews', engine, if_exists='append', index=False, chunksize=1000)\n",
    "df5.to_sql('Sellers', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "\n",
    "print(\"✅ All tables uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "96375816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tables uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "df6.to_sql('Category_Name_Translation', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "print(\"✅ All tables uploaded successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9d33578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tables uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df7.to_sql('Products', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "print(\"✅ All tables uploaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5c86f004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All tables uploaded successfully!\n"
     ]
    }
   ],
   "source": [
    "df8.to_sql('Order_Items', engine, if_exists='append', index=False, chunksize=1000)\n",
    "\n",
    "print(\"✅ All tables uploaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
